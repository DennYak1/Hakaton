{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPuws9/pKVOnwSg715k8cEQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Margo-10/Hakaton/blob/main/model1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pdfminer.six\n",
        "\n",
        "!pip install python-docx\n",
        "\n",
        "!sudo apt install tesseract-ocr\n",
        "!pip install pytesseract\n",
        "\n",
        "!pip install pillow\n",
        "\n",
        "!pip install PyPDF2\n",
        "\n",
        "!sudo apt-get update\n",
        "!sudo apt-get install -y poppler-utils\n",
        "\n",
        "!pip install pdf2image"
      ],
      "metadata": {
        "id": "yIoFOttlzqCv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kzpzwbJnoYZ5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "from pdfminer.high_level import extract_text as pdfminer_extract\n",
        "import pytesseract\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import docx\n",
        "from docx import Document\n",
        "\n",
        "from PyPDF2 import PdfReader\n",
        "import warnings\n",
        "from pdf2image import convert_from_path\n",
        "from PyPDF2 import PdfReader, PdfWriter\n",
        "\n",
        "import zipfile\n",
        "import os\n",
        "import shutil\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1xbA3glwHCcU5RjDEvuqgZxWNzec2MRs9"
      ],
      "metadata": {
        "id": "haLYGLtUxzHI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with zipfile.ZipFile('/content/hackaton_main.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/hackaton')\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZYg7d_0JqKjT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs(\"/content/tmp\", exist_ok=True)"
      ],
      "metadata": {
        "id": "3VBPe3MZ2nHW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = '/content/hackaton/hackaton'"
      ],
      "metadata": {
        "id": "83AlqCXY1-l_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def check_cropbox(file_path):\n",
        "    with open(file_path, 'rb') as f:\n",
        "        reader = PdfReader(f)\n",
        "\n",
        "        for page in reader.pages:\n",
        "            if '/CropBox' not in page:\n",
        "                warnings.warn(\"CropBox missing, using MediaBox\") # чекните\n",
        "    return pdfminer_extract(file_path)\n",
        "\n",
        "\n",
        "def fix_cropbox(file_path):\n",
        "    reader = PdfReader(file_path)\n",
        "    writer = PdfWriter()\n",
        "\n",
        "    for page in reader.pages:\n",
        "        if '/CropBox' not in page:\n",
        "            page.cropbox = page.mediabox\n",
        "        writer.add_page(page)\n",
        "\n",
        "    fixed_path = os.path.join(os.path.dirname(file_path), \"fixed_\" + os.path.basename(file_path))\n",
        "    with open(fixed_path, 'wb') as f:\n",
        "        writer.write(f)\n",
        "    return fixed_path\n",
        "\n"
      ],
      "metadata": {
        "id": "02kVaQ0oqK7C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def is_pdf_textual(file_path):\n",
        "    try:\n",
        "        text = pdfminer_extract(file_path)\n",
        "        return bool(text.strip())\n",
        "    except:\n",
        "        return False\n",
        "\n",
        "def pdf(file_path):\n",
        "    try:\n",
        "        if not is_pdf_textual(file_path):\n",
        "            print(\"PDF не содержит текста, запускаем OCR...\")\n",
        "            return pdf_c_ocr(file_path)\n",
        "        text = pdfminer_extract(file_path)\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        print(f\"Ошибка обработки PDF: {e}\")\n",
        "        return \"\"\n",
        "    finally:\n",
        "\n",
        "        fixed_path = os.path.join(os.path.dirname(file_path), \"fixed_\" + os.path.basename(file_path))\n",
        "        if os.path.exists(fixed_path):\n",
        "            os.remove(fixed_path)\n",
        "\n",
        "\n",
        "def pdf_c_ocr(file_path):\n",
        "    try:\n",
        "\n",
        "        images = convert_from_path(file_path, dpi=300)\n",
        "        text = \"\"\n",
        "        for i, img in enumerate(images):\n",
        "            try:\n",
        "                text += pytesseract.image_to_string(img, lang='rus+eng') + \"\\n\"\n",
        "            except Exception as ocr_error:\n",
        "                print(f\"OCR ошибка на странице {i + 1}: {ocr_error}\")\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        print(f\"Ошибка конвертации PDF в изображение: {e}\")\n",
        "        return \"\"\n"
      ],
      "metadata": {
        "id": "LO0rq40O28QD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def doc(file_path):\n",
        "    try:\n",
        "        print(f\"Конвертация DOC в DOCX: {file_path}\")\n",
        "        tmp_dir = \"/content/tmp\"\n",
        "        os.makedirs(tmp_dir, exist_ok=True)\n",
        "        os.system(f\"libreoffice --headless --convert-to docx --outdir {tmp_dir} {file_path}\")\n",
        "\n",
        "        new_path = os.path.join(tmp_dir, os.path.splitext(os.path.basename(file_path))[0] + \".docx\")\n",
        "        if not os.path.exists(new_path):\n",
        "            print(f\"Ошибка: файл {new_path} не создан\")\n",
        "            return \"\"\n",
        "\n",
        "        return docx_text(new_path)\n",
        "    except Exception as e:\n",
        "        print(f\"Ошибка конвертации DOC: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "def docx_text(file_path):\n",
        "    \"\"\"Чтение DOCX файлов\"\"\"\n",
        "    try:\n",
        "        doc = Document(file_path)\n",
        "        return \"\\n\".join([para.text for para in doc.paragraphs])\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Ошибка чтения DOCX: {e}\")\n",
        "        return \"\""
      ],
      "metadata": {
        "id": "BHLeMWDA0qRH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def excel(file_path):\n",
        "    try:\n",
        "        text = \"\"\n",
        "        dfs = pd.read_excel(file_path, sheet_name=None)\n",
        "\n",
        "        for sheet, df in dfs.items():\n",
        "            df = df.map(lambda x: '' if pd.isna(x) else x)\n",
        "            text += f\"Лист: {sheet}\\n{df.to_string()}\\n\\n\"\n",
        "        return text\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Excel ошибка: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "\n",
        "def all_text(file_path):\n",
        "    if file_path.lower().endswith('.pdf'):\n",
        "        return pdf(file_path)\n",
        "\n",
        "    elif file_path.lower().endswith('.docx'):\n",
        "        return docx_text(file_path)\n",
        "\n",
        "    elif file_path.lower().endswith('.doc'):\n",
        "        return doc(file_path)\n",
        "\n",
        "    elif file_path.lower().endswith('.xlsx'):\n",
        "        return excel(file_path)\n",
        "\n",
        "    else:\n",
        "        print(f\"Неизвестный формат файла: {file_path}\")\n",
        "        return \"\"\n",
        "\n",
        "\n",
        "def clean_text(text):\n",
        "    return re.sub(r'\\s+', ' ', text).strip()\n",
        "\n"
      ],
      "metadata": {
        "id": "IZhNMWTPqukw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cleanup_tmp():\n",
        "    shutil.rmtree(\"/content/tmp\", ignore_errors=True)\n",
        "    os.makedirs(\"/content/tmp\", exist_ok=True)"
      ],
      "metadata": {
        "id": "e4cVtSYzDHVV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def main():\n",
        "\n",
        "    if not os.path.exists(data_dir):\n",
        "        print(f\"Ошибка: папки {data_dir} не существует!\")\n",
        "        return\n",
        "\n",
        "    file_paths = [os.path.join(data_dir, f) for f in os.listdir(data_dir)\n",
        "                  if f.lower().endswith(('.pdf', '.docx', '.doc', '.xlsx'))]\n",
        "\n",
        "    if not file_paths:\n",
        "        print(\"В указанной папке нет файлов поддерживаемых форматов\")\n",
        "        return\n",
        "\n",
        "    print(f\"\\nНайдено {len(file_paths)} файлов для обработки в папке {data_dir}:\")\n",
        "\n",
        "    for i, fp in enumerate(file_paths, 1):\n",
        "        print(f\"{i}. {os.path.basename(fp)}\")\n",
        "\n",
        "    documents = []\n",
        "\n",
        "    for file_path in file_paths:\n",
        "        filename = os.path.basename(file_path)\n",
        "        print(f\"\\nОбработка файла: {filename}\")\n",
        "\n",
        "        try:\n",
        "            text = all_text(file_path)\n",
        "            if text:\n",
        "                cleaned = clean_text(text)\n",
        "                preview = cleaned[:100] + ('...' if len(cleaned) > 100 else '')\n",
        "                documents.append({\n",
        "                    'name': filename,\n",
        "                    'text': cleaned,\n",
        "                    'preview': preview\n",
        "                })\n",
        "                print(f\"Успешно извлечено. Превьюшка: {preview}\")\n",
        "\n",
        "            else:\n",
        "                print(\"Не удалось извлечь текст\")\n",
        "                documents.append({\n",
        "                    'name': filename,\n",
        "                    'text': '',\n",
        "                    'preview': 'Нет текста'\n",
        "                })\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Ошибка обработки: {e}\")\n",
        "            documents.append({\n",
        "                'name': filename,\n",
        "                'text': '',\n",
        "                'preview': f'Ошибка обработки: {str(e)}'\n",
        "            })\n",
        "\n",
        "    # Вывод полных результатов\n",
        "    print(\"\\n\" + \"=\" * 50)\n",
        "    print(\"Полные результаты обработки:\")\n",
        "\n",
        "    for doc in documents:\n",
        "        print(f\"\\nФайл: {doc['name']}\")\n",
        "        print(f\"Превьюшенька (первые 100 символов): {doc['preview']}\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "    # Поиск по ключевым словам\n",
        "    while True:\n",
        "        query = input(\"\\nВведите ключевые слова для поиска (или 'q' для выхода): \").strip()\n",
        "        if query.lower() == 'q':\n",
        "            break\n",
        "\n",
        "        if not query:\n",
        "            continue\n",
        "\n",
        "        keywords = re.sub(r'[^\\w\\s]', '', query).lower().split()\n",
        "        results = [d for d in documents\n",
        "                   if all(kw in d['text'].lower() for kw in keywords)]\n",
        "\n",
        "        if results:\n",
        "            print(f\"\\nНайдено {len(results)} совпадений:\")\n",
        "            for res in results:\n",
        "                print(f\"- {res['name']}\")\n",
        "                print(f\"  Совпадение: {res['preview']}\")\n",
        "        else:\n",
        "            print(\"Совпадений не найдено\")\n",
        "\n",
        "    cleanup_tmp()\n",
        "    print(\"\\nПрограмма завершена.\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6-a5cnLq4nM",
        "outputId": "23d32600-4af3-4fe1-ba62-e7de6bcbbba7"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Найдено 23 файлов для обработки в папке /content/hackaton/hackaton:\n",
            "1. Улисс.doc\n",
            "2. Фролов_К_В_Динамика_и_прочность_машин_МЭ_том_I_3_книга_1_1994.pdf\n",
            "3. MOCK_DATA-7.xlsx\n",
            "4. MOCK_DATA-5.xlsx\n",
            "5. Фролов_К_В_Двигатели_внутреннего_сгорания_МЭ_том_IV_14_2013.pdf\n",
            "6. MOCK_DATA-9.xlsx\n",
            "7. Завтрак-у-Тиффани.doc\n",
            "8. Фролов_К_В_Горные_машины_МЭ_том_IV_24_2010.pdf\n",
            "9. MOCK_DATA.xlsx\n",
            "10. MOCK_DATA-10.xlsx\n",
            "11. MOCK_DATA-6.xlsx\n",
            "12. 06_Великие_музеи_мира_Эрмитаж_Часть_1_2011.pdf\n",
            "13. MOCK_DATA-4.xlsx\n",
            "14. 04_Великие_музеи_мира_Египетский_музей_2011.pdf\n",
            "15. MOCK_DATA-2.xlsx\n",
            "16. MOCK_DATA-3.xlsx\n",
            "17. 05_Великие_музеи_мира_Метрополитен_2011.pdf\n",
            "18. MOCK_DATA-8.xlsx\n",
            "19. 03_Великие_музеи_мира_Лувр_Париж_2011.pdf\n",
            "20. 02_Великие_музеи_мира_Прадо_Мадрид_2011.pdf\n",
            "21. Фролов_К_В_Авиационные_двигатели_МЭ_том_IV_21_книга_3_2010.pdf\n",
            "22. Приваловские-миллионы.doc\n",
            "23. Хладнокровное-убийство.doc\n",
            "\n",
            "Обработка файла: Улисс.doc\n",
            "Конвертация DOC в DOCX: /content/hackaton/hackaton/Улисс.doc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PpmL8es-7S01"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}