{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMTYXri/tClhfigc0Tl4hqK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Margo-10/Hakaton/blob/main/model1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pdfminer.six\n",
        "\n",
        "!pip install python-docx\n",
        "\n",
        "!sudo apt install tesseract-ocr\n",
        "!pip install pytesseract\n",
        "\n",
        "!pip install pillow\n",
        "\n",
        "!pip install PyPDF2\n",
        "\n",
        "!sudo apt-get update\n",
        "!sudo apt-get install -y poppler-utils\n",
        "\n",
        "!pip install pdf2image"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yIoFOttlzqCv",
        "outputId": "55673ddd-3f1d-4081-d387-442ca4a062d0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pdfminer.six in /usr/local/lib/python3.11/dist-packages (20250327)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six) (3.4.1)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six) (43.0.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=36.0.0->pdfminer.six) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six) (2.22)\n",
            "Requirement already satisfied: python-docx in /usr/local/lib/python3.11/dist-packages (1.1.2)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (5.3.1)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (4.13.1)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "tesseract-ocr is already the newest version (4.1.1-2.1build1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 32 not upgraded.\n",
            "Requirement already satisfied: pytesseract in /usr/local/lib/python3.11/dist-packages (0.3.13)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from pytesseract) (24.2)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from pytesseract) (11.1.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.1.0)\n",
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.11/dist-packages (3.0.1)\n",
            "Hit:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:3 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:4 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:6 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:9 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "poppler-utils is already the newest version (22.02.0-2ubuntu0.7).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 32 not upgraded.\n",
            "Requirement already satisfied: pdf2image in /usr/local/lib/python3.11/dist-packages (1.17.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from pdf2image) (11.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "kzpzwbJnoYZ5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "from pdfminer.high_level import extract_text as pdfminer_extract\n",
        "import pytesseract\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import docx\n",
        "from docx import Document\n",
        "\n",
        "from PyPDF2 import PdfReader\n",
        "import warnings\n",
        "from pdf2image import convert_from_path\n",
        "from PyPDF2 import PdfReader, PdfWriter\n",
        "\n",
        "import zipfile\n",
        "import os\n",
        "import shutil\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1xbA3glwHCcU5RjDEvuqgZxWNzec2MRs9"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "haLYGLtUxzHI",
        "outputId": "f294cec9-6490-431e-a388-97f2fb706068"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1xbA3glwHCcU5RjDEvuqgZxWNzec2MRs9\n",
            "From (redirected): https://drive.google.com/uc?id=1xbA3glwHCcU5RjDEvuqgZxWNzec2MRs9&confirm=t&uuid=a7a676c3-acec-4e02-9f79-4de48932e3a1\n",
            "To: /content/hackaton_main.zip\n",
            "100% 786M/786M [00:10<00:00, 74.2MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with zipfile.ZipFile('/content/hackaton_main.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/hackaton')\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZYg7d_0JqKjT"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs(\"/content/tmp\", exist_ok=True)"
      ],
      "metadata": {
        "id": "3VBPe3MZ2nHW"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = '/content/hackaton/hackaton'"
      ],
      "metadata": {
        "id": "83AlqCXY1-l_"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def check_cropbox(file_path):\n",
        "    with open(file_path, 'rb') as f:\n",
        "        reader = PdfReader(f)\n",
        "\n",
        "        for page in reader.pages:\n",
        "            if '/CropBox' not in page:\n",
        "                warnings.warn(\"CropBox missing, using MediaBox\") # чекните\n",
        "    return pdfminer_extract(file_path)\n",
        "\n",
        "\n",
        "def fix_cropbox(file_path):\n",
        "    reader = PdfReader(file_path)\n",
        "    writer = PdfWriter()\n",
        "\n",
        "    for page in reader.pages:\n",
        "        if '/CropBox' not in page:\n",
        "            page.cropbox = page.mediabox\n",
        "        writer.add_page(page)\n",
        "\n",
        "    fixed_path = os.path.join(os.path.dirname(file_path), \"fixed_\" + os.path.basename(file_path))\n",
        "    with open(fixed_path, 'wb') as f:\n",
        "        writer.write(f)\n",
        "    return fixed_path\n",
        "\n"
      ],
      "metadata": {
        "id": "02kVaQ0oqK7C"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pdf(file_path):\n",
        "    try:\n",
        "        fixed_path = fix_cropbox(file_path)\n",
        "        text = pdfminer_extract(fixed_path)\n",
        "\n",
        "        if not text.strip():\n",
        "            print(\"Текст пустой, запускаем OCR...\")\n",
        "            return pdf_c_ocr(fixed_path)\n",
        "        return text\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Ошибка PDF: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "\n",
        "def pdf_c_ocr(file_path):\n",
        "    try:\n",
        "        images = convert_from_path(file_path, dpi=300, poppler_path=poppler_path)\n",
        "        text = \"\"\n",
        "        for i, img in enumerate(images):\n",
        "            try:\n",
        "                text += pytesseract.image_to_string(img, lang='rus+eng') + \"\\n\"\n",
        "\n",
        "            except Exception as ocr_error:\n",
        "                print(f\"OCR ошибка на странице {i + 1}: {ocr_error}\")\n",
        "        return text\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Ошибка конвертации PDF в изображение: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "\n",
        "# def pdf(file_path):\n",
        "#     try:\n",
        "#         #  быстрое извлечение текста\n",
        "#         try:\n",
        "#             text = pdfminer_extract(file_path)\n",
        "#             if text.strip():\n",
        "#                 return text\n",
        "#         except:\n",
        "#             pass\n",
        "\n",
        "#         print(\"PDF не содержит текста или ошибка, запускаем OCR...\")\n",
        "#         return pdf_c_ocr(file_path)\n",
        "\n",
        "#     except Exception as e:\n",
        "#         print(f\"Ошибка обработки PDF: {e}\")\n",
        "#         return \"\"\n",
        "\n",
        "\n",
        "# def pdf_c_ocr(file_path):\n",
        "#     try:\n",
        "\n",
        "#         images = convert_from_path(file_path, dpi=300)\n",
        "#         text = \"\"\n",
        "#         for i, img in enumerate(images):\n",
        "#             try:\n",
        "#                 text += pytesseract.image_to_string(img, lang='rus+eng') + \"\\n\"\n",
        "#             except Exception as ocr_error:\n",
        "#                 print(f\"OCR ошибка на странице {i + 1}: {ocr_error}\")\n",
        "#         return text\n",
        "#     except Exception as e:\n",
        "#         print(f\"Ошибка конвертации PDF в изображение: {e}\")\n",
        "#         return \"\"\n"
      ],
      "metadata": {
        "id": "LO0rq40O28QD"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def doc(file_path):\n",
        "    try:\n",
        "        print(f\"Конвертация DOC в DOCX: {file_path}\")\n",
        "        tmp_dir = \"/content/tmp\"\n",
        "        os.makedirs(tmp_dir, exist_ok=True)\n",
        "        os.system(f\"libreoffice --headless --convert-to docx --outdir {tmp_dir} {file_path}\")\n",
        "\n",
        "        new_path = os.path.join(tmp_dir, os.path.splitext(os.path.basename(file_path))[0] + \".docx\")\n",
        "        if not os.path.exists(new_path):\n",
        "            print(f\"Ошибка: файл {new_path} не создан\")\n",
        "            return \"\"\n",
        "\n",
        "        return docx_text(new_path)\n",
        "    except Exception as e:\n",
        "        print(f\"Ошибка конвертации DOC: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "def docx_text(file_path):\n",
        "    \"\"\"Чтение DOCX файлов\"\"\"\n",
        "    try:\n",
        "        doc = Document(file_path)\n",
        "        return \"\\n\".join([para.text for para in doc.paragraphs])\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Ошибка чтения DOCX: {e}\")\n",
        "        return \"\""
      ],
      "metadata": {
        "id": "BHLeMWDA0qRH"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def excel(file_path):\n",
        "    try:\n",
        "        text = \"\"\n",
        "        dfs = pd.read_excel(file_path, sheet_name=None)\n",
        "\n",
        "        for sheet, df in dfs.items():\n",
        "            df = df.map(lambda x: '' if pd.isna(x) else x)\n",
        "            text += f\"Лист: {sheet}\\n{df.to_string()}\\n\\n\"\n",
        "        return text\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Excel ошибка: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "\n",
        "def all_text(file_path):\n",
        "    if file_path.lower().endswith('.pdf'):\n",
        "        return pdf(file_path)\n",
        "\n",
        "    elif file_path.lower().endswith('.docx'):\n",
        "        return docx_text(file_path)\n",
        "\n",
        "    elif file_path.lower().endswith('.doc'):\n",
        "        return doc(file_path)\n",
        "\n",
        "    elif file_path.lower().endswith('.xlsx'):\n",
        "        return excel(file_path)\n",
        "\n",
        "    else:\n",
        "        print(f\"Неизвестный формат файла: {file_path}\")\n",
        "        return \"\"\n",
        "\n",
        "\n",
        "def clean_text(text):\n",
        "    return re.sub(r'\\s+', ' ', text).strip()\n",
        "\n"
      ],
      "metadata": {
        "id": "IZhNMWTPqukw"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cleanup_tmp():\n",
        "    shutil.rmtree(\"/content/tmp\", ignore_errors=True)\n",
        "    os.makedirs(\"/content/tmp\", exist_ok=True)"
      ],
      "metadata": {
        "id": "e4cVtSYzDHVV"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def main():\n",
        "\n",
        "    if not os.path.exists(data_dir):\n",
        "        print(f\"Ошибка: папки {data_dir} не существует!\")\n",
        "        return\n",
        "\n",
        "    file_paths = [os.path.join(data_dir, f) for f in os.listdir(data_dir)\n",
        "                  if f.lower().endswith(('.pdf', '.docx', '.doc', '.xlsx'))]\n",
        "\n",
        "    if not file_paths:\n",
        "        print(\"В указанной папке нет файлов поддерживаемых форматов\")\n",
        "        return\n",
        "\n",
        "    print(f\"\\nНайдено {len(file_paths)} файлов для обработки в папке {data_dir}:\")\n",
        "\n",
        "    for i, fp in enumerate(file_paths, 1):\n",
        "        print(f\"{i}. {os.path.basename(fp)}\")\n",
        "\n",
        "    documents = []\n",
        "\n",
        "    for file_path in file_paths:\n",
        "        filename = os.path.basename(file_path)\n",
        "        print(f\"\\nОбработка файла: {filename}\")\n",
        "\n",
        "        try:\n",
        "            text = all_text(file_path)\n",
        "            if text:\n",
        "                cleaned = clean_text(text)\n",
        "                preview = cleaned[:100] + ('...' if len(cleaned) > 100 else '')\n",
        "                documents.append({\n",
        "                    'name': filename,\n",
        "                    'text': cleaned,\n",
        "                    'preview': preview\n",
        "                })\n",
        "                print(f\"Успешно извлечено. Превьюшка: {preview}\")\n",
        "\n",
        "            else:\n",
        "                print(\"Не удалось извлечь текст\")\n",
        "                documents.append({\n",
        "                    'name': filename,\n",
        "                    'text': '',\n",
        "                    'preview': 'Нет текста'\n",
        "                })\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Ошибка обработки: {e}\")\n",
        "            documents.append({\n",
        "                'name': filename,\n",
        "                'text': '',\n",
        "                'preview': f'Ошибка обработки: {str(e)}'\n",
        "            })\n",
        "\n",
        "    # Вывод полных результатов\n",
        "    print(\"\\n\" + \"=\" * 50)\n",
        "    print(\"Полные результаты обработки:\")\n",
        "\n",
        "    for doc in documents:\n",
        "        print(f\"\\nФайл: {doc['name']}\")\n",
        "        print(f\"Превьюшенька (первые 100 символов): {doc['preview']}\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "    # Поиск по ключевым словам\n",
        "    while True:\n",
        "        query = input(\"\\nВведите ключевые слова для поиска (или 'q' для выхода): \").strip()\n",
        "        if query.lower() == 'q':\n",
        "            break\n",
        "\n",
        "        if not query:\n",
        "            continue\n",
        "\n",
        "        keywords = re.sub(r'[^\\w\\s]', '', query).lower().split()\n",
        "        results = [d for d in documents\n",
        "                   if all(kw in d['text'].lower() for kw in keywords)]\n",
        "\n",
        "        if results:\n",
        "            print(f\"\\nНайдено {len(results)} совпадений:\")\n",
        "            for res in results:\n",
        "                print(f\"- {res['name']}\")\n",
        "                print(f\"  Совпадение: {res['preview']}\")\n",
        "        else:\n",
        "            print(\"Совпадений не найдено\")\n",
        "\n",
        "    cleanup_tmp()\n",
        "    print(\"\\nПрограмма завершена.\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6-a5cnLq4nM",
        "outputId": "3e882fc1-c7c5-48b1-adf7-a3c789ccbe00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Найдено 23 файлов для обработки в папке /content/hackaton/hackaton:\n",
            "1. Улисс.doc\n",
            "2. Фролов_К_В_Динамика_и_прочность_машин_МЭ_том_I_3_книга_1_1994.pdf\n",
            "3. MOCK_DATA-7.xlsx\n",
            "4. MOCK_DATA-5.xlsx\n",
            "5. Фролов_К_В_Двигатели_внутреннего_сгорания_МЭ_том_IV_14_2013.pdf\n",
            "6. MOCK_DATA-9.xlsx\n",
            "7. Завтрак-у-Тиффани.doc\n",
            "8. Фролов_К_В_Горные_машины_МЭ_том_IV_24_2010.pdf\n",
            "9. MOCK_DATA.xlsx\n",
            "10. MOCK_DATA-10.xlsx\n",
            "11. MOCK_DATA-6.xlsx\n",
            "12. 06_Великие_музеи_мира_Эрмитаж_Часть_1_2011.pdf\n",
            "13. MOCK_DATA-4.xlsx\n",
            "14. 04_Великие_музеи_мира_Египетский_музей_2011.pdf\n",
            "15. MOCK_DATA-2.xlsx\n",
            "16. MOCK_DATA-3.xlsx\n",
            "17. 05_Великие_музеи_мира_Метрополитен_2011.pdf\n",
            "18. MOCK_DATA-8.xlsx\n",
            "19. 03_Великие_музеи_мира_Лувр_Париж_2011.pdf\n",
            "20. 02_Великие_музеи_мира_Прадо_Мадрид_2011.pdf\n",
            "21. Фролов_К_В_Авиационные_двигатели_МЭ_том_IV_21_книга_3_2010.pdf\n",
            "22. Приваловские-миллионы.doc\n",
            "23. Хладнокровное-убийство.doc\n",
            "\n",
            "Обработка файла: Улисс.doc\n",
            "Конвертация DOC в DOCX: /content/hackaton/hackaton/Улисс.doc\n"
          ]
        }
      ]
    }
  ]
}